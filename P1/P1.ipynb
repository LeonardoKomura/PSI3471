{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ecd89c57",
   "metadata": {},
   "outputs": [],
   "source": [
    "## P1 - Parte Computacional - PSI3471\n",
    "## Aluno: Leonardo Isao Komura - NUSP: 11261656"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f577434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "270ecde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Leitura dos arquivos\n",
    "ecg_treino = pd.read_csv(\"ecg_treino.csv\")\n",
    "rotulos_treino = pd.read_csv(\"rotulos_treino.csv\")\n",
    "n_rotulos_treino = pd.read_csv(\"n_rotulos_treino.csv\")  \n",
    "\n",
    "ecg_teste = pd.read_csv(\"ecg_teste.csv\")\n",
    "rotulos_teste = pd.read_csv(\"rotulos_teste.csv\")\n",
    "n_rotulos_teste = pd.read_csv(\"n_rotulos_teste.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f26ad67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformação em formato numpy\n",
    "treino = ecg_treino.to_numpy()\n",
    "r_treino = rotulos_treino.to_numpy()\n",
    "n_treino = n_rotulos_treino.to_numpy()\n",
    "\n",
    "teste = ecg_teste.to_numpy()\n",
    "r_teste = rotulos_teste.to_numpy()\n",
    "n_teste = n_rotulos_teste.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "7e21e152",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-0.345 -0.345 -0.345 ... -0.295 -0.29 0.0]\n",
      " [-0.31 -0.31 -0.31 ... 0.635 0.265 0.0]\n",
      " [-0.125 -0.125 -0.125 ... -0.01 0.04 0.0]\n",
      " ...\n",
      " [-0.69 -0.69 -0.69 ... -0.16 -0.155 0.0]\n",
      " [-0.93 -0.93 -0.93 ... -0.55 -0.555 0.0]\n",
      " [-0.38 -0.38 -0.38 ... -0.59 -0.59 0.0]]\n"
     ]
    }
   ],
   "source": [
    "# Deletando os \"nomes\" dos pacientes\n",
    "treino = np.delete(treino, 0, axis=1)\n",
    "r_treino = np.delete(r_treino, 0, axis=1)\n",
    "n_treino = np.delete(n_treino, 0, axis=1)\n",
    "\n",
    "teste = np.delete(teste, 0, axis=1)\n",
    "r_teste = np.delete(r_teste, 0, axis=1)\n",
    "n_teste = np.delete(n_teste, 0, axis=1)\n",
    "\n",
    "print(treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "1f37d05f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Média do comprimento dos 50 primeiros batimentos de todos pacientes:  293\n"
     ]
    }
   ],
   "source": [
    "# Cálculo da média do \"comprimento\" dos 50 primeiros batimentos de todos pacientes\n",
    "nn = 0.0\n",
    "for i in range(0, len(n_treino)):\n",
    "    for j in range(50):\n",
    "        nn = nn + abs(n_treino[i,j] - n_treino[i, j+1])\n",
    "nn_average = math.ceil(nn/(50*len(n_treino)))\n",
    "print(\"Média do comprimento dos 50 primeiros batimentos de todos pacientes: \", nn_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3de6ccdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocando cada batimento numa posição de um tensor\n",
    "n_pontos = 650000\n",
    "batimentos = int(n_pontos/nn_average)\n",
    "tensor = np.ndarray(shape=(len(treino), batimentos, nn_average-1), dtype=float)\n",
    "for i in range(len(treino)):\n",
    "    for j in range(batimentos):\n",
    "        tensor[i,j] = treino[i, j*nn_average : (j+1)*nn_average-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "cb4ce446",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leona\\AppData\\Local\\Temp\\ipykernel_32944\\1469831185.py:4: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  tensor[i,j] = np.fft.fft(tensor[i,j])\n"
     ]
    }
   ],
   "source": [
    "# Transformada de Fourier da amostra\n",
    "for i in range(len(treino)):\n",
    "    for j in range(batimentos):\n",
    "        tensor[i,j] = np.fft.fft(tensor[i,j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19d208f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e97b84af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cálculo da média do \"comprimento\" dos 5 primeiros batimentos de cada paciente e adicionando na primeira coluna\n",
    "for i in range(0, len(n_treino)):\n",
    "    nn = 0.0\n",
    "    for j in range(5):\n",
    "        nn = nn + abs(n_treino[i,j] - n_treino[i, j+1])\n",
    "    nn_average = math.ceil(nn/5)\n",
    "    #ft_treino[i,0] = nn_average\n",
    "    \n",
    "for i in range(0, len(n_teste)):\n",
    "    nn = 0.0\n",
    "    for j in range(5):\n",
    "        nn = nn + abs(n_teste[i,j] - n_teste[i, j+1])\n",
    "    nn_average = math.ceil(nn/5)\n",
    "    #ft_teste[i,0] = nn_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7a8b69f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     0         1           2           3           4           5     \\\n",
      "0   326.0   932.270   81.729275   16.953190   71.655701   37.107040   \n",
      "1   370.0   458.445   64.047180   74.960232   56.200345   48.670853   \n",
      "2   347.0   888.025   48.018409   34.903937   37.268001   31.381784   \n",
      "3   236.0  1319.685  336.154171  182.599576   51.806113    7.201617   \n",
      "4   254.0  2725.010   95.813548   59.146026   35.257334   24.144408   \n",
      "5   410.0   586.790   39.299156   23.291510   18.722261   21.581286   \n",
      "6   364.0  1464.690   61.929660   58.126685   41.894234   30.967210   \n",
      "7   272.0  2969.160  117.537617   18.449536  126.646190   86.901135   \n",
      "8   304.0  2854.820  100.158811   25.371796   51.955578    9.735718   \n",
      "9   333.0  2565.570   47.733328   76.590257  234.550956  109.994679   \n",
      "10  232.0  2383.620   93.940405   37.907058   41.467538   29.387012   \n",
      "11  441.0  2164.985  223.473675   80.878745   30.939598   52.954324   \n",
      "12  253.0   535.370   75.901854   42.519269   34.308745   36.043972   \n",
      "13  235.0   275.785  262.474054  301.022193  155.810190   54.754916   \n",
      "14  241.0  1106.120   68.947468   24.956638   17.602545    3.706850   \n",
      "15  355.0   615.040   32.941285   56.466727   28.907192  308.986932   \n",
      "16  227.0   355.005  134.393136   54.811291   25.556939  185.978818   \n",
      "17  230.0   417.475   86.856494  119.401604   16.206959   35.309037   \n",
      "18  195.0   473.470   82.588945   56.525544   26.851584    8.897137   \n",
      "19  298.0  1763.580   51.220679   34.075615   16.279982   12.711000   \n",
      "20  274.0  1625.055   19.774638   16.995720   29.994001   25.518508   \n",
      "21  265.0   853.425   42.624898   35.587406   48.175102    9.128782   \n",
      "\n",
      "          6           7           8           9     ...        2921  \\\n",
      "0    11.235887   18.800408    4.711857   11.712691  ...    4.127832   \n",
      "1    23.638422   28.516016    7.381511  264.210458  ...   25.771361   \n",
      "2    15.204087   22.872811   41.721330   71.659955  ...   30.770709   \n",
      "3    51.769043   37.070906   29.001994   19.625073  ...   32.887624   \n",
      "4     4.806321   21.646863    6.444574   23.335991  ...   27.073787   \n",
      "5     7.567968   27.012590  114.545092   23.910966  ...    3.519490   \n",
      "6    19.163536   42.808248   25.325588  153.507099  ...   30.722879   \n",
      "7    73.385782   88.101644   39.269829   37.616300  ...   90.057819   \n",
      "8    43.690422    6.127373   25.777719   59.072047  ...  247.618171   \n",
      "9    84.187239  226.680944  145.822242   81.559570  ...  163.796901   \n",
      "10   24.933377   23.068469   30.337607   30.162965  ...   40.109023   \n",
      "11   37.444074  102.046305  197.609407   41.299011  ...   27.042156   \n",
      "12   18.873630   17.048797    2.362259   37.426523  ...   36.278225   \n",
      "13    9.219190   56.382645    9.883721   24.989410  ...   89.932760   \n",
      "14   15.811889    4.271668    0.728313    6.508975  ...    3.427445   \n",
      "15   59.914443   57.903588   69.540794  273.624643  ...   80.390678   \n",
      "16  147.256092  101.565654   68.731472  135.774146  ...   72.413995   \n",
      "17   10.984991   18.774199    9.718031    7.578083  ...   12.665003   \n",
      "18    6.510508    6.441019    9.394323    2.192280  ...    3.735493   \n",
      "19   20.069909   10.038403   16.794420   16.032697  ...   23.243337   \n",
      "20   15.942119   15.022293   19.114962   40.574993  ...   88.406724   \n",
      "21   34.302930   22.425698   48.407079   45.023001  ...  111.693688   \n",
      "\n",
      "          2922        2923        2924        2925        2926        2927  \\\n",
      "0    62.021560   11.712691    4.711857   18.800408   11.235887   37.107040   \n",
      "1    35.248778  264.210458    7.381511   28.516016   23.638422   48.670853   \n",
      "2    68.475550   71.659955   41.721330   22.872811   15.204087   31.381784   \n",
      "3    20.966026   19.625073   29.001994   37.070906   51.769043    7.201617   \n",
      "4    19.727324   23.335991    6.444574   21.646863    4.806321   24.144408   \n",
      "5     7.916055   23.910966  114.545092   27.012590    7.567968   21.581286   \n",
      "6    14.948462  153.507099   25.325588   42.808248   19.163536   30.967210   \n",
      "7    51.921458   37.616300   39.269829   88.101644   73.385782   86.901135   \n",
      "8    90.322942   59.072047   25.777719    6.127373   43.690422    9.735718   \n",
      "9   183.988597   81.559570  145.822242  226.680944   84.187239  109.994679   \n",
      "10   25.401966   30.162965   30.337607   23.068469   24.933377   29.387012   \n",
      "11   39.539694   41.299011  197.609407  102.046305   37.444074   52.954324   \n",
      "12    6.342531   37.426523    2.362259   17.048797   18.873630   36.043972   \n",
      "13   56.856220   24.989410    9.883721   56.382645    9.219190   54.754916   \n",
      "14    6.408326    6.508975    0.728313    4.271668   15.811889    3.706850   \n",
      "15   82.659328  273.624643   69.540794   57.903588   59.914443  308.986932   \n",
      "16   24.696301  135.774146   68.731472  101.565654  147.256092  185.978818   \n",
      "17    0.700682    7.578083    9.718031   18.774199   10.984991   35.309037   \n",
      "18    9.303687    2.192280    9.394323    6.441019    6.510508    8.897137   \n",
      "19   17.239955   16.032697   16.794420   10.038403   20.069909   12.711000   \n",
      "20   33.606981   40.574993   19.114962   15.022293   15.942119   25.518508   \n",
      "21   22.450929   45.023001   48.407079   22.425698   34.302930    9.128782   \n",
      "\n",
      "          2928        2929        2930  \n",
      "0    71.655701   16.953190   81.729275  \n",
      "1    56.200345   74.960232   64.047180  \n",
      "2    37.268001   34.903937   48.018409  \n",
      "3    51.806113  182.599576  336.154171  \n",
      "4    35.257334   59.146026   95.813548  \n",
      "5    18.722261   23.291510   39.299156  \n",
      "6    41.894234   58.126685   61.929660  \n",
      "7   126.646190   18.449536  117.537617  \n",
      "8    51.955578   25.371796  100.158811  \n",
      "9   234.550956   76.590257   47.733328  \n",
      "10   41.467538   37.907058   93.940405  \n",
      "11   30.939598   80.878745  223.473675  \n",
      "12   34.308745   42.519269   75.901854  \n",
      "13  155.810190  301.022193  262.474054  \n",
      "14   17.602545   24.956638   68.947468  \n",
      "15   28.907192   56.466727   32.941285  \n",
      "16   25.556939   54.811291  134.393136  \n",
      "17   16.206959  119.401604   86.856494  \n",
      "18   26.851584   56.525544   82.588945  \n",
      "19   16.279982   34.075615   51.220679  \n",
      "20   29.994001   16.995720   19.774638  \n",
      "21   48.175102   35.587406   42.624898  \n",
      "\n",
      "[22 rows x 2931 columns]\n"
     ]
    }
   ],
   "source": [
    "## Retornando para dataframe\n",
    "#df_treino = pd.DataFrame(abs(ft_treino))\n",
    "#df_teste  = pd.DataFrame(abs(ft_teste))\n",
    "#print(df_treino)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4cded369",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'float' object has no attribute 'Module'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32md:\\-FACULDADE-\\PSI3471\\P1\\P1.ipynb Cell 12'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/d%3A/-FACULDADE-/PSI3471/P1/P1.ipynb#ch0000011?line=0'>1</a>\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39mMLP\u001b[39;00m(nn\u001b[39m.\u001b[39;49mModule):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/-FACULDADE-/PSI3471/P1/P1.ipynb#ch0000011?line=1'>2</a>\u001b[0m     \u001b[39mdef\u001b[39;00m \u001b[39m__init__\u001b[39m(\u001b[39mself\u001b[39m, input_size, n_hidden, output_size):\n\u001b[0;32m      <a href='vscode-notebook-cell:/d%3A/-FACULDADE-/PSI3471/P1/P1.ipynb#ch0000011?line=2'>3</a>\u001b[0m         \u001b[39msuper\u001b[39m(MLP, \u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__init__\u001b[39m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'float' object has no attribute 'Module'"
     ]
    }
   ],
   "source": [
    "class MLP(nn.Module):\n",
    "    def __init__(self, input_size, n_hidden, output_size):\n",
    "        super(MLP, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.network = nn.Sequential(\n",
    "            nn.Linear(input_size, n_hidden), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden, n_hidden-10), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden-10, n_hidden-10), \n",
    "            nn.ELU(),\n",
    "            nn.Linear(n_hidden-10, output_size), \n",
    "            nn.LogSoftmax(dim=1)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, self.input_size)\n",
    "        return self.network(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71cb247",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26ef9d5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch, model):\n",
    "    # Coloca o modelo em modo de treinamento\n",
    "    model.train()\n",
    "    \n",
    "    # Loop sobre os mini-batches, fornecidos pelo DataLoader train_loader\n",
    "    for batch_idx, (data, target) in enumerate(ft_teste):      \n",
    "        # Para mandar os dados para o device (GPU ou CPU definido anteriormente), usamos o método .to(device)\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Ajuste de dimensões\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "\n",
    "        # Necessário no PyTorch, para limpar o cache de gradientes acumulados\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        # Cálculo da saída\n",
    "        output = model(data)\n",
    "        \n",
    "        # nll_loss é a função custo da entropia cruzada\n",
    "        loss = F.cross_entropy(output, target)\n",
    "        \n",
    "        # cálculo dos gradientes\n",
    "        loss.backward()\n",
    "        \n",
    "        # atualização dos parâmetros do modelo\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Exibe o status do treinamento\n",
    "        if batch_idx % 100 == 0:\n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))\n",
    "            \n",
    "def test(model):\n",
    "    # Coloca o modelo em modo de teste\n",
    "    model.eval()\n",
    "    \n",
    "    # Variáveis usadas para contabilizar o valor da função custo e número de acertos\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    \n",
    "    # Loop sobre os mini-batches, fornecidos pelo DataLoader test_loader\n",
    "    for data, target in ft_teste:\n",
    "        \n",
    "        # Para mandar os dados para o device (GPU ou CPU definido anteriormente), usamos o método .to(device)     \n",
    "        data, target = data.to(device), target.to(device)\n",
    "        \n",
    "        # Ajuste de dimensões\n",
    "        data = data.view(-1, 1, 28, 28)\n",
    "        \n",
    "        # Cálculo da saída\n",
    "        output = model(data)\n",
    "\n",
    "        # Valor da função custo\n",
    "        test_loss += F.cross_entropy(output, target, reduction='sum').item() # sum up batch loss                                                               \n",
    "\n",
    "        # Cálculo do número de acertos\n",
    "        pred = output.data.max(1, keepdim=True)[1] # get the index of the max log-probability                                                                 \n",
    "        correct += pred.eq(target.data.view_as(pred)).cpu().sum().item()\n",
    "\n",
    "    # Mostra o desempenho obtido no teste    \n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
  },
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
