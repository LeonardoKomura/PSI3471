{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import glob\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def le(nomearq):\n",
    "    with open(nomearq,\"r\") as f:\n",
    "        linhas=f.readlines()\n",
    "    linha0=linhas[0].split()\n",
    "    nl=int(linha0[0]); nc=int(linha0[1])\n",
    "    a=np.empty((nl,nc),dtype=np.float32)\n",
    "    for l in range(nl):\n",
    "        linha=linhas[l+1].split()\n",
    "        for c in range(nc):\n",
    "            a[l,c]=np.float32(linha[c])\n",
    "    return a\n",
    "ax = le(\"ax.txt\"); ay = le(\"ay.txt\")\n",
    "qx = le(\"qx.txt\"); qy = le(\"qy.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Qtde de treino: 617\n",
      "Qtde de validação: 69\n"
     ]
    }
   ],
   "source": [
    "# Validação cruzada\n",
    "from sklearn.model_selection import train_test_split\n",
    "x_train, x_val, y_train, y_val = train_test_split(ax, ay, test_size = 0.1, random_state=1)\n",
    "print('Qtde de treino: {}'.format(len(x_train)))\n",
    "print('Qtde de validação: {}'.format(len(x_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Criando a MLP\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='relu', input_shape=(len(ax[0]),)))\n",
    "model.add(Dense(5, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=\"Adam\",\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "7/7 [==============================] - 1s 40ms/step - loss: 1.0450 - accuracy: 0.3834 - val_loss: 0.9683 - val_accuracy: 0.5072\n",
      "Epoch 2/200\n",
      "7/7 [==============================] - 0s 15ms/step - loss: 0.9736 - accuracy: 0.5437 - val_loss: 0.9089 - val_accuracy: 0.5942\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.9092 - accuracy: 0.5845 - val_loss: 0.8565 - val_accuracy: 0.5942\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.8564 - accuracy: 0.5918 - val_loss: 0.8126 - val_accuracy: 0.6087\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.8093 - accuracy: 0.5933 - val_loss: 0.7755 - val_accuracy: 0.6232\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.7715 - accuracy: 0.5991 - val_loss: 0.7445 - val_accuracy: 0.6087\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.7406 - accuracy: 0.6006 - val_loss: 0.7184 - val_accuracy: 0.6232\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.7155 - accuracy: 0.6079 - val_loss: 0.6979 - val_accuracy: 0.6377\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6976 - accuracy: 0.6268 - val_loss: 0.6783 - val_accuracy: 0.6667\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6838 - accuracy: 0.6370 - val_loss: 0.6629 - val_accuracy: 0.6812\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6741 - accuracy: 0.6414 - val_loss: 0.6536 - val_accuracy: 0.6957\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6659 - accuracy: 0.6516 - val_loss: 0.6456 - val_accuracy: 0.7101\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6591 - accuracy: 0.6691 - val_loss: 0.6377 - val_accuracy: 0.6957\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6527 - accuracy: 0.6837 - val_loss: 0.6310 - val_accuracy: 0.7246\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6460 - accuracy: 0.7012 - val_loss: 0.6245 - val_accuracy: 0.7246\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6394 - accuracy: 0.7157 - val_loss: 0.6180 - val_accuracy: 0.7536\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6326 - accuracy: 0.7289 - val_loss: 0.6111 - val_accuracy: 0.7536\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6252 - accuracy: 0.7391 - val_loss: 0.6038 - val_accuracy: 0.7681\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.6176 - accuracy: 0.7507 - val_loss: 0.5958 - val_accuracy: 0.7681\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.6096 - accuracy: 0.7551 - val_loss: 0.5872 - val_accuracy: 0.7826\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.6009 - accuracy: 0.7624 - val_loss: 0.5782 - val_accuracy: 0.7826\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5920 - accuracy: 0.7638 - val_loss: 0.5690 - val_accuracy: 0.7826\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5822 - accuracy: 0.7697 - val_loss: 0.5586 - val_accuracy: 0.7826\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5711 - accuracy: 0.7799 - val_loss: 0.5475 - val_accuracy: 0.7971\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.5574 - accuracy: 0.8047 - val_loss: 0.5336 - val_accuracy: 0.8116\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.5391 - accuracy: 0.8484 - val_loss: 0.5024 - val_accuracy: 0.9420\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.5120 - accuracy: 0.9096 - val_loss: 0.4746 - val_accuracy: 0.9275\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4899 - accuracy: 0.9052 - val_loss: 0.4618 - val_accuracy: 0.8986\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4762 - accuracy: 0.8848 - val_loss: 0.4473 - val_accuracy: 0.8986\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4602 - accuracy: 0.9082 - val_loss: 0.4309 - val_accuracy: 0.9275\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.4457 - accuracy: 0.9329 - val_loss: 0.4162 - val_accuracy: 0.9420\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4315 - accuracy: 0.9373 - val_loss: 0.4013 - val_accuracy: 0.9710\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.4162 - accuracy: 0.9300 - val_loss: 0.3865 - val_accuracy: 0.9710\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.4001 - accuracy: 0.9344 - val_loss: 0.3719 - val_accuracy: 0.9710\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3842 - accuracy: 0.9431 - val_loss: 0.3564 - val_accuracy: 0.9710\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3691 - accuracy: 0.9563 - val_loss: 0.3414 - val_accuracy: 0.9710\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3541 - accuracy: 0.9606 - val_loss: 0.3272 - val_accuracy: 0.9855\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.3397 - accuracy: 0.9606 - val_loss: 0.3140 - val_accuracy: 0.9710\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.3257 - accuracy: 0.9665 - val_loss: 0.3009 - val_accuracy: 0.9710\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.3122 - accuracy: 0.9694 - val_loss: 0.2885 - val_accuracy: 0.9710\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2992 - accuracy: 0.9708 - val_loss: 0.2767 - val_accuracy: 0.9710\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.2867 - accuracy: 0.9723 - val_loss: 0.2653 - val_accuracy: 0.9710\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2744 - accuracy: 0.9723 - val_loss: 0.2544 - val_accuracy: 0.9855\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2625 - accuracy: 0.9752 - val_loss: 0.2438 - val_accuracy: 0.9855\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2509 - accuracy: 0.9767 - val_loss: 0.2339 - val_accuracy: 0.9855\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2400 - accuracy: 0.9781 - val_loss: 0.2245 - val_accuracy: 0.9855\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2292 - accuracy: 0.9810 - val_loss: 0.2156 - val_accuracy: 0.9855\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2191 - accuracy: 0.9810 - val_loss: 0.2066 - val_accuracy: 0.9855\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.2093 - accuracy: 0.9796 - val_loss: 0.1981 - val_accuracy: 0.9855\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.2000 - accuracy: 0.9796 - val_loss: 0.1900 - val_accuracy: 0.9855\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1911 - accuracy: 0.9825 - val_loss: 0.1826 - val_accuracy: 0.9855\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1824 - accuracy: 0.9840 - val_loss: 0.1755 - val_accuracy: 0.9855\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1742 - accuracy: 0.9840 - val_loss: 0.1676 - val_accuracy: 0.9855\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1661 - accuracy: 0.9883 - val_loss: 0.1602 - val_accuracy: 0.9855\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1588 - accuracy: 0.9898 - val_loss: 0.1531 - val_accuracy: 1.0000\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.9898 - val_loss: 0.1462 - val_accuracy: 1.0000\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1445 - accuracy: 0.9898 - val_loss: 0.1392 - val_accuracy: 1.0000\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.1375 - accuracy: 0.9869 - val_loss: 0.1321 - val_accuracy: 1.0000\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1307 - accuracy: 0.9869 - val_loss: 0.1242 - val_accuracy: 1.0000\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9869 - val_loss: 0.1167 - val_accuracy: 1.0000\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1154 - accuracy: 0.9883 - val_loss: 0.1120 - val_accuracy: 1.0000\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.1093 - accuracy: 0.9883 - val_loss: 0.1075 - val_accuracy: 1.0000\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.1046 - accuracy: 0.9883 - val_loss: 0.1037 - val_accuracy: 1.0000\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.1006 - accuracy: 0.9883 - val_loss: 0.0997 - val_accuracy: 1.0000\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0968 - accuracy: 0.9883 - val_loss: 0.0965 - val_accuracy: 1.0000\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0935 - accuracy: 0.9883 - val_loss: 0.0932 - val_accuracy: 1.0000\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0905 - accuracy: 0.9883 - val_loss: 0.0902 - val_accuracy: 1.0000\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0878 - accuracy: 0.9883 - val_loss: 0.0875 - val_accuracy: 1.0000\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0851 - accuracy: 0.9883 - val_loss: 0.0846 - val_accuracy: 1.0000\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0824 - accuracy: 0.9898 - val_loss: 0.0821 - val_accuracy: 1.0000\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9898 - val_loss: 0.0797 - val_accuracy: 1.0000\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0777 - accuracy: 0.9913 - val_loss: 0.0775 - val_accuracy: 1.0000\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9913 - val_loss: 0.0751 - val_accuracy: 1.0000\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0734 - accuracy: 0.9913 - val_loss: 0.0732 - val_accuracy: 1.0000\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0715 - accuracy: 0.9913 - val_loss: 0.0712 - val_accuracy: 1.0000\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0696 - accuracy: 0.9913 - val_loss: 0.0694 - val_accuracy: 1.0000\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0678 - accuracy: 0.9913 - val_loss: 0.0676 - val_accuracy: 1.0000\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0660 - accuracy: 0.9913 - val_loss: 0.0659 - val_accuracy: 1.0000\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0645 - accuracy: 0.9913 - val_loss: 0.0642 - val_accuracy: 1.0000\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0628 - accuracy: 0.9913 - val_loss: 0.0627 - val_accuracy: 1.0000\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0613 - accuracy: 0.9927 - val_loss: 0.0611 - val_accuracy: 1.0000\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0599 - accuracy: 0.9927 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0585 - accuracy: 0.9927 - val_loss: 0.0582 - val_accuracy: 1.0000\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0572 - accuracy: 0.9927 - val_loss: 0.0570 - val_accuracy: 1.0000\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0559 - accuracy: 0.9927 - val_loss: 0.0557 - val_accuracy: 1.0000\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0547 - accuracy: 0.9927 - val_loss: 0.0544 - val_accuracy: 1.0000\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0535 - accuracy: 0.9927 - val_loss: 0.0532 - val_accuracy: 1.0000\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0523 - accuracy: 0.9927 - val_loss: 0.0521 - val_accuracy: 1.0000\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0513 - accuracy: 0.9927 - val_loss: 0.0511 - val_accuracy: 1.0000\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0503 - accuracy: 0.9927 - val_loss: 0.0501 - val_accuracy: 1.0000\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0492 - accuracy: 0.9927 - val_loss: 0.0490 - val_accuracy: 1.0000\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0482 - accuracy: 0.9927 - val_loss: 0.0479 - val_accuracy: 1.0000\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0472 - accuracy: 0.9927 - val_loss: 0.0468 - val_accuracy: 1.0000\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0463 - accuracy: 0.9927 - val_loss: 0.0458 - val_accuracy: 1.0000\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0454 - accuracy: 0.9927 - val_loss: 0.0448 - val_accuracy: 1.0000\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0445 - accuracy: 0.9927 - val_loss: 0.0439 - val_accuracy: 1.0000\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0437 - accuracy: 0.9927 - val_loss: 0.0431 - val_accuracy: 1.0000\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0430 - accuracy: 0.9927 - val_loss: 0.0424 - val_accuracy: 1.0000\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0421 - accuracy: 0.9927 - val_loss: 0.0415 - val_accuracy: 1.0000\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0413 - accuracy: 0.9927 - val_loss: 0.0408 - val_accuracy: 1.0000\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0406 - accuracy: 0.9927 - val_loss: 0.0400 - val_accuracy: 1.0000\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0398 - accuracy: 0.9927 - val_loss: 0.0392 - val_accuracy: 1.0000\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0392 - accuracy: 0.9942 - val_loss: 0.0386 - val_accuracy: 1.0000\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0385 - accuracy: 0.9942 - val_loss: 0.0378 - val_accuracy: 1.0000\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0378 - accuracy: 0.9942 - val_loss: 0.0372 - val_accuracy: 1.0000\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0372 - accuracy: 0.9927 - val_loss: 0.0365 - val_accuracy: 1.0000\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0367 - accuracy: 0.9927 - val_loss: 0.0356 - val_accuracy: 1.0000\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0359 - accuracy: 0.9942 - val_loss: 0.0351 - val_accuracy: 1.0000\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0353 - accuracy: 0.9942 - val_loss: 0.0345 - val_accuracy: 1.0000\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0347 - accuracy: 0.9942 - val_loss: 0.0341 - val_accuracy: 1.0000\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0342 - accuracy: 0.9942 - val_loss: 0.0335 - val_accuracy: 1.0000\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0339 - accuracy: 0.9942 - val_loss: 0.0331 - val_accuracy: 1.0000\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0332 - accuracy: 0.9956 - val_loss: 0.0325 - val_accuracy: 1.0000\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0326 - accuracy: 0.9956 - val_loss: 0.0320 - val_accuracy: 1.0000\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0320 - accuracy: 0.9956 - val_loss: 0.0312 - val_accuracy: 1.0000\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0318 - accuracy: 0.9942 - val_loss: 0.0304 - val_accuracy: 1.0000\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0311 - accuracy: 0.9956 - val_loss: 0.0299 - val_accuracy: 1.0000\n",
      "Epoch 118/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0307 - accuracy: 0.9971 - val_loss: 0.0297 - val_accuracy: 1.0000\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0302 - accuracy: 0.9971 - val_loss: 0.0292 - val_accuracy: 1.0000\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0297 - accuracy: 0.9971 - val_loss: 0.0286 - val_accuracy: 1.0000\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0292 - accuracy: 0.9971 - val_loss: 0.0281 - val_accuracy: 1.0000\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0289 - accuracy: 0.9971 - val_loss: 0.0276 - val_accuracy: 1.0000\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0284 - accuracy: 0.9971 - val_loss: 0.0272 - val_accuracy: 1.0000\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0281 - accuracy: 0.9971 - val_loss: 0.0269 - val_accuracy: 1.0000\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0277 - accuracy: 0.9971 - val_loss: 0.0266 - val_accuracy: 1.0000\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0272 - accuracy: 0.9971 - val_loss: 0.0262 - val_accuracy: 1.0000\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0268 - accuracy: 0.9971 - val_loss: 0.0257 - val_accuracy: 1.0000\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0265 - accuracy: 0.9971 - val_loss: 0.0252 - val_accuracy: 1.0000\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0261 - accuracy: 0.9971 - val_loss: 0.0248 - val_accuracy: 1.0000\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0258 - accuracy: 0.9971 - val_loss: 0.0244 - val_accuracy: 1.0000\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0255 - accuracy: 0.9971 - val_loss: 0.0242 - val_accuracy: 1.0000\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0250 - accuracy: 0.9971 - val_loss: 0.0239 - val_accuracy: 1.0000\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0248 - accuracy: 0.9971 - val_loss: 0.0235 - val_accuracy: 1.0000\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0245 - accuracy: 0.9971 - val_loss: 0.0228 - val_accuracy: 1.0000\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0240 - accuracy: 0.9971 - val_loss: 0.0226 - val_accuracy: 1.0000\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0237 - accuracy: 0.9971 - val_loss: 0.0222 - val_accuracy: 1.0000\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0234 - accuracy: 0.9971 - val_loss: 0.0221 - val_accuracy: 1.0000\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0232 - accuracy: 0.9971 - val_loss: 0.0220 - val_accuracy: 1.0000\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0228 - accuracy: 0.9971 - val_loss: 0.0216 - val_accuracy: 1.0000\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0225 - accuracy: 0.9971 - val_loss: 0.0211 - val_accuracy: 1.0000\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0223 - accuracy: 0.9971 - val_loss: 0.0208 - val_accuracy: 1.0000\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0220 - accuracy: 0.9971 - val_loss: 0.0205 - val_accuracy: 1.0000\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0217 - accuracy: 0.9971 - val_loss: 0.0202 - val_accuracy: 1.0000\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0215 - accuracy: 0.9971 - val_loss: 0.0200 - val_accuracy: 1.0000\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0212 - accuracy: 0.9971 - val_loss: 0.0196 - val_accuracy: 1.0000\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0209 - accuracy: 0.9971 - val_loss: 0.0194 - val_accuracy: 1.0000\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0208 - accuracy: 0.9971 - val_loss: 0.0193 - val_accuracy: 1.0000\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0205 - accuracy: 0.9971 - val_loss: 0.0188 - val_accuracy: 1.0000\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0202 - accuracy: 0.9971 - val_loss: 0.0184 - val_accuracy: 1.0000\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0199 - accuracy: 0.9971 - val_loss: 0.0182 - val_accuracy: 1.0000\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0198 - accuracy: 0.9971 - val_loss: 0.0180 - val_accuracy: 1.0000\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0195 - accuracy: 0.9971 - val_loss: 0.0181 - val_accuracy: 1.0000\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0193 - accuracy: 0.9971 - val_loss: 0.0176 - val_accuracy: 1.0000\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0190 - accuracy: 0.9971 - val_loss: 0.0175 - val_accuracy: 1.0000\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0188 - accuracy: 0.9971 - val_loss: 0.0173 - val_accuracy: 1.0000\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0186 - accuracy: 0.9971 - val_loss: 0.0169 - val_accuracy: 1.0000\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0184 - accuracy: 0.9971 - val_loss: 0.0168 - val_accuracy: 1.0000\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0182 - accuracy: 0.9971 - val_loss: 0.0167 - val_accuracy: 1.0000\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0180 - accuracy: 0.9971 - val_loss: 0.0164 - val_accuracy: 1.0000\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0178 - accuracy: 0.9971 - val_loss: 0.0162 - val_accuracy: 1.0000\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0176 - accuracy: 0.9971 - val_loss: 0.0160 - val_accuracy: 1.0000\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0175 - accuracy: 0.9971 - val_loss: 0.0159 - val_accuracy: 1.0000\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0172 - accuracy: 0.9971 - val_loss: 0.0155 - val_accuracy: 1.0000\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0170 - accuracy: 0.9971 - val_loss: 0.0152 - val_accuracy: 1.0000\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0168 - accuracy: 0.9971 - val_loss: 0.0151 - val_accuracy: 1.0000\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0167 - accuracy: 0.9971 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 11ms/step - loss: 0.0166 - accuracy: 0.9971 - val_loss: 0.0149 - val_accuracy: 1.0000\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0163 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0162 - accuracy: 0.9971 - val_loss: 0.0146 - val_accuracy: 1.0000\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0160 - accuracy: 0.9971 - val_loss: 0.0142 - val_accuracy: 1.0000\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0158 - accuracy: 0.9971 - val_loss: 0.0140 - val_accuracy: 1.0000\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0156 - accuracy: 0.9971 - val_loss: 0.0138 - val_accuracy: 1.0000\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0155 - accuracy: 0.9971 - val_loss: 0.0137 - val_accuracy: 1.0000\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0153 - accuracy: 0.9971 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0152 - accuracy: 0.9971 - val_loss: 0.0135 - val_accuracy: 1.0000\n",
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0150 - accuracy: 0.9971 - val_loss: 0.0133 - val_accuracy: 1.0000\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0149 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0132 - val_accuracy: 1.0000\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 8ms/step - loss: 0.0147 - accuracy: 0.9971 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0145 - accuracy: 0.9971 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0143 - accuracy: 0.9985 - val_loss: 0.0127 - val_accuracy: 1.0000\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0142 - accuracy: 0.9985 - val_loss: 0.0128 - val_accuracy: 1.0000\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0140 - accuracy: 0.9971 - val_loss: 0.0123 - val_accuracy: 1.0000\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0139 - accuracy: 0.9971 - val_loss: 0.0122 - val_accuracy: 1.0000\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0138 - accuracy: 0.9971 - val_loss: 0.0120 - val_accuracy: 1.0000\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0136 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0135 - accuracy: 1.0000 - val_loss: 0.0118 - val_accuracy: 1.0000\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0133 - accuracy: 1.0000 - val_loss: 0.0115 - val_accuracy: 1.0000\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 4ms/step - loss: 0.0132 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0131 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0130 - accuracy: 1.0000 - val_loss: 0.0113 - val_accuracy: 1.0000\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0112 - val_accuracy: 1.0000\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0128 - accuracy: 1.0000 - val_loss: 0.0111 - val_accuracy: 1.0000\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0126 - accuracy: 1.0000 - val_loss: 0.0109 - val_accuracy: 1.0000\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0125 - accuracy: 1.0000 - val_loss: 0.0107 - val_accuracy: 1.0000\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0124 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0123 - accuracy: 1.0000 - val_loss: 0.0108 - val_accuracy: 1.0000\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 7ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 0.0103 - val_accuracy: 1.0000\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 5ms/step - loss: 0.0121 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 6ms/step - loss: 0.0119 - accuracy: 1.0000 - val_loss: 0.0102 - val_accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "batch_size = 100\n",
    "epochs = 200\n",
    "history = model.fit(ax, ay,\n",
    "                    batch_size=batch_size,\n",
    "                    epochs=epochs,\n",
    "                    validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "#Plot the confusion matrix. Set Normalize = True/False\n",
    "def plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        cm = np.around(cm, decimals=2)\n",
    "        cm[np.isnan(cm)] = 0.0\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, cm[i, j],\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22/22 [==============================] - 0s 1ms/step\n",
      "Classification Report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      0.99       377\n",
      "           1       1.00      0.99      0.99       309\n",
      "\n",
      "    accuracy                           0.99       686\n",
      "   macro avg       0.99      0.99      0.99       686\n",
      "weighted avg       0.99      0.99      0.99       686\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x720 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "target_names = ['0', '1']\n",
    "qp = (model.predict(qx) > 0.5)\n",
    "cm = confusion_matrix(qp,qy)\n",
    "plot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n",
    "\n",
    "print('Classification Report')\n",
    "print(classification_report(qp, qy, target_names=target_names))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9be826744cc5714b462ad0c8de88bfa6f016a48973c6317b9546595d1685cabb"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
